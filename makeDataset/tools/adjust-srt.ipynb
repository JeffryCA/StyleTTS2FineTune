{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"Converts seconds to SRT timestamp format.\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = seconds % 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return f\"{hours:02}:{minutes:02}:{int(seconds):02},{milliseconds:03}\"\n",
    "\n",
    "def json_to_srt(json_path, srt_path):\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    with open(srt_path, 'w') as file:\n",
    "        for index, segment in enumerate(data['segments'], start=1):\n",
    "            start = format_time(segment['start'])\n",
    "            end = format_time(segment['end'])\n",
    "            text = segment['text']\n",
    "            file.write(f\"{index}\\n{start} --> {end}\\n{text}\\n\\n\")\n",
    "\n",
    "    return srt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def adjust_transcript_segments(file_path, save_dir=None, min_segment_duration=2, max_segment_duration=12, max_gap_for_merge=0.5, verbose=False):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Original segments:\")\n",
    "        for segment in data['segments']:\n",
    "            print(f\"{round(segment['end'] - segment['start'], 2)}s: {segment['text']}\")\n",
    "\n",
    "    segments = data['segments']\n",
    "    merged_segments = []\n",
    "\n",
    "    # First pass: merge segments that are close together if it results in staying under max duration\n",
    "    temp_segment = None\n",
    "    for segment in segments:\n",
    "        if temp_segment is None:\n",
    "            temp_segment = segment\n",
    "        else:\n",
    "            gap = segment['start'] - temp_segment['end']\n",
    "            combined_duration = segment['end'] - temp_segment['start']\n",
    "\n",
    "            if gap <= max_gap_for_merge and combined_duration <= max_segment_duration:\n",
    "                # Extend the current segment if they are close enough and under the max duration\n",
    "                temp_segment['end'] = segment['end']\n",
    "                temp_segment['text'] += \" \" + segment['text']\n",
    "                temp_segment['words'].extend(segment['words'])\n",
    "            else:\n",
    "                merged_segments.append(temp_segment)\n",
    "                temp_segment = segment\n",
    "    if temp_segment:\n",
    "        merged_segments.append(temp_segment)\n",
    "\n",
    "    # Second pass: examine each segment for its length, merge with previous or next based on conditions\n",
    "    final_segments = []\n",
    "    i = 0\n",
    "    while i < len(merged_segments):\n",
    "        segment = merged_segments[i]\n",
    "        duration = segment['end'] - segment['start']\n",
    "\n",
    "        if duration < min_segment_duration:\n",
    "            # Try to merge with previous segment if possible\n",
    "            if i > 0 and (segment['end'] - merged_segments[i - 1]['start'] <= max_segment_duration):\n",
    "                merged_segments[i - 1]['end'] = segment['end']\n",
    "                merged_segments[i - 1]['text'] += \" \" + segment['text']\n",
    "                merged_segments[i - 1]['words'].extend(segment['words'])\n",
    "            elif i + 1 < len(merged_segments) and (merged_segments[i + 1]['end'] - segment['start'] <= max_segment_duration):\n",
    "                # Merge with next segment if previous is not possible\n",
    "                merged_segments[i + 1]['start'] = segment['start']\n",
    "                merged_segments[i + 1]['text'] = segment['text'] + \" \" + merged_segments[i + 1]['text']\n",
    "                merged_segments[i + 1]['words'] = segment['words'] + merged_segments[i + 1]['words']\n",
    "                i += 1  # Skip the next segment since it's now merged\n",
    "        else:\n",
    "            final_segments.append(segment)\n",
    "        i += 1\n",
    "\n",
    "    data['segments'] = final_segments\n",
    "\n",
    "    # Check for any segments that are still too long\n",
    "    for segment in final_segments:\n",
    "        duration = segment['end'] - segment['start']\n",
    "        if duration > max_segment_duration:\n",
    "            print(\n",
    "                f\"Warning: Segment longer than {max_segment_duration} seconds {duration:.2f}: {segment['text']}\"\n",
    "            )\n",
    "        elif duration < min_segment_duration:\n",
    "            print(\n",
    "                f\"Warning: Segment shorter than {min_segment_duration} seconds {duration:.2f}: {segment['text']}\"\n",
    "            )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nAdjusted segments:\")\n",
    "        for segment in data['segments']:\n",
    "            print(f\"{round(segment['end'] - segment['start'], 2)}s: {segment['text']}\")\n",
    "\n",
    "    # Save the adjusted data back to a new JSON file\n",
    "    if save_dir:\n",
    "        save_path = os.path.join(save_dir, os.path.basename(file_path))\n",
    "        if verbose:\n",
    "            print(f\"Saving adjusted transcript to {save_path}\")\n",
    "        with open(save_path, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment, silence\n",
    "import json\n",
    "\n",
    "def find_silences(audio_path, min_silence_len=1000, silence_thresh=-40):\n",
    "    \"\"\"Detects silences in an audio file and returns the intervals.\"\"\"\n",
    "    sound = AudioSegment.from_file(audio_path)\n",
    "    silence_intervals = silence.detect_silence(\n",
    "        sound, \n",
    "        min_silence_len=min_silence_len, \n",
    "        silence_thresh=silence_thresh\n",
    "    )\n",
    "    # Convert from milliseconds to seconds\n",
    "    silence_intervals = [(start / 1000.0, end / 1000.0) for start, end in silence_intervals]\n",
    "    return silence_intervals\n",
    "\n",
    "\n",
    "def add_intelligent_padding(data, max_padding=0.5):\n",
    "    \"\"\" Adjust the start and end times of each segment to add padding without overlapping speech.\n",
    "        'max_padding' is the maximum padding to add to each side of a segment if space allows.\n",
    "    \"\"\"\n",
    "    segments = data['segments']\n",
    "    if not segments:\n",
    "        return data\n",
    "    \n",
    "    # Process each segment except the last\n",
    "    for i in range(len(segments) - 1):\n",
    "        current_segment = segments[i]\n",
    "        next_segment = segments[i + 1]\n",
    "        \n",
    "        # Calculate available gap between the current segment end and the next segment start\n",
    "        gap = next_segment['start'] - current_segment['end']\n",
    "        \n",
    "        # Determine the amount of padding to apply\n",
    "        padding = min(max_padding, gap / 2)  # Half the gap, but no more than max_padding\n",
    "        \n",
    "        # Apply padding to the end of the current segment and the start of the next\n",
    "        current_segment['end'] += padding\n",
    "        next_segment['start'] -= padding\n",
    "\n",
    "    # Optionally, add padding to the last segment\n",
    "    segments[-1]['end'] += max_padding\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def add_buffer_padding(data, buffer_time=0.2, max_allowed_gap=0.3):\n",
    "    segments = data['segments']\n",
    "\n",
    "    new_segments = []\n",
    "    for i in range(len(segments)):\n",
    "        current_segment = segments[i]\n",
    "        end_time = current_segment['end']\n",
    "\n",
    "        if i < len(segments) - 1:\n",
    "            next_segment = segments[i + 1]\n",
    "            next_start_time = next_segment['start']\n",
    "            gap_to_next = next_start_time - end_time\n",
    "\n",
    "            if gap_to_next > max_allowed_gap:\n",
    "                end_time += buffer_time\n",
    "            else:\n",
    "                adjustment = min(buffer_time, gap_to_next // 2)\n",
    "                end_time += adjustment\n",
    "\n",
    "        else:  # Last segment\n",
    "            end_time += buffer_time\n",
    "\n",
    "        current_segment['end'] = end_time\n",
    "        new_segments.append(current_segment)\n",
    "\n",
    "\n",
    "    data['segments'] = new_segments\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "json_file = './srt/test.json'\n",
    "srt_folder = \"srt\"\n",
    "audio_folder = \"wav\"\n",
    "audio_file = json_file.replace(srt_folder, audio_folder).replace('json', 'wav')\n",
    "\n",
    "# Call the function with the path to your JSON file\n",
    "data_1 = adjust_transcript_segments(\n",
    "    json_file,\n",
    "    min_segment_duration=1.7,\n",
    "    max_segment_duration=12, \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# print average, min, max gap between segments\n",
    "gaps = [data_1['segments'][i+1]['start'] - data_1['segments'][i]['end'] for i in range(len(data_1['segments'])-1)]\n",
    "print(f\"Average gap between segments: {sum(gaps)/len(gaps):.2f}\")\n",
    "print(f\"Minimum gap between segments: {min(gaps):.2f}\")\n",
    "print(f\"Maximum gap between segments: {max(gaps):.2f}\")\n",
    "\n",
    "\n",
    "data_2 = add_intelligent_padding(deepcopy(data_1), max_padding=0.3)\n",
    "data_3 = add_buffer_padding(deepcopy(data_1), buffer_time=0.3, max_allowed_gap=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# print segment durations\n",
    "for segments in zip(\n",
    "        data_1['segments'], \n",
    "        data_2['segments'], \n",
    "        data_3['segments'], \n",
    "    ):\n",
    "\n",
    "    print(segments[0]['text'])\n",
    "\n",
    "    for segment in segments:\n",
    "        print(f\"{segment['start']:.2f}, {segment['end']:.2f}, {segment['end']-segment['start']:.2f}\")\n",
    "\n",
    "    for segment in segments:\n",
    "        display(\n",
    "            AudioSegment.from_file(audio_file )[segment['start']*1000:segment['end']*1000]\n",
    "        )\n",
    "    print('---')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "book = \".\"\n",
    "srt_folder = \"srt\"\n",
    "audio_folder = \"wav\"\n",
    "processed_folder = \"processed\"\n",
    "\n",
    "srt_list = glob.glob(f\"{book}/{srt_folder}/*.json\")  # Gets a list of all srt files\n",
    "srt_list.sort() \n",
    "\n",
    "for file in srt_list[:]:\n",
    "    print(file)\n",
    "    data = adjust_transcript_segments(\n",
    "        file, \n",
    "        # f\"{book}/{processed_folder}\", \n",
    "        min_segment_duration=1.7,\n",
    "        max_segment_duration=12\n",
    "    )\n",
    "\n",
    "    # find silences\n",
    "    audio_file = file.replace(srt_folder, audio_folder).replace('json', 'wav')\n",
    "    data = add_intelligent_padding(data, max_padding=0.3)\n",
    "\n",
    "    # save the adjusted data back to a new JSON file\n",
    "    save_path = file.replace(srt_folder, processed_folder)\n",
    "    with open(save_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "    # save srt file\n",
    "    json_to_srt(save_path, save_path.replace('json', 'srt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
